{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIF Data Exploration\n",
    "\n",
    "This notebook will guide you through the steps involved in collecting solar-induced fluorescence (SIF) data from NASA's Goddard Earth Sciences Data and Information Services Center (GES DISC), an online archive that stores data from the Orbiting Carbon Observatory-3 (OCO-3) spacecraft, among others.\n",
    "\n",
    "The first code block below will simply import some necessary helper functions for exploring and displaying the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import textwrap\n",
    "\n",
    "# Add src directory containing helper code to sys.path\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from geosif import GesDiscDownloader, plot_samples, plot_gridded, create_gridded_raster\n",
    "\n",
    "# an additional helper function for displaying long lists\n",
    "def wrapped_markdown_list(my_list, width=160):\n",
    "    wrapped_text = textwrap.fill(\", \".join(my_list), width=width)\n",
    "    display(Markdown(f\"```\\n{wrapped_text}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Getting granules from GES DISC\n",
    "\n",
    "The GES DISC stores various datasets associated with the OCO-2 and OCO-3 instruments, and in this training we will be focusing on the \"SIF Lite\" datasets as they have already received L2 processing to extract chlorophyll fluorescence signatures in the O2-A (757 nm) and O2-B  (771 nm) bands. Data is served through an OpenDAP interface that provides a browsing experience similar to looking at a directory tree. You can navigate this directory tree yourself here: [https://oco2.gesdisc.eosdis.nasa.gov/opendap/](https://oco2.gesdisc.eosdis.nasa.gov/opendap/)\n",
    "\n",
    "A \"granule\" is an instrument data file, typically in netCDF (.nc or .nc4) format, containing a set of related variables from a time range of observations. Granules in general can be daily or subdaily in time cadence. In the case of the OCO3_L2_Lite_SIF.11r dataset we are are looking at today, individual netCDFs on GES DISC correspond to a signal day worth of instrument observations. \n",
    "\n",
    "The pydap module is able to lazily evaluate data in the archive without downloading it until needed, allowing us to explore the variables in a given granule before we download it. By the way, you may see a pydap warning when loading the data, this is no concern.\n",
    "\n",
    "**If you want to look at a different dataset, change the value of the dataset variable and re-run this cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gathering datasets on GES DISC...\")\n",
    "dl = GesDiscDownloader()\n",
    "\n",
    "dataset = \"OCO3_L2_Lite_SIF.11r\" # See Step V for an example with \"OCO2_L2_Lite_FP.11.2r\"\n",
    "print(f\"Getting time range for {dataset} data...\")\n",
    "timerange = dl.get_dataset_timerange(dataset)\n",
    "print(\n",
    "    f\"{dataset} has time range {timerange[0].strftime('%Y-%m-%d')} to {timerange[1].strftime('%Y-%m-%d')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you want to look at a different date, change the date specified in `data_date` and re-run the cell below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OCO-3 SIF Lite V11r product from December 1, 2019\n",
    "data_date = datetime(2019, 12, 1) # Replace with a different date if you'd like\n",
    "granule = dl.get_granule_by_date(dataset, data_date)\n",
    "print(f\"\\n\\nThe {dataset} granule from {data_date.strftime('%d/%m/%Y')} has the following variables:\")\n",
    "\n",
    "wrapped_markdown_list(list(granule.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Download Variables and Plot\n",
    "\n",
    "As mentioned previously, the SIF granules contain different many different variables needed for further analysis. To get a quick sense of where observations were acquired on this particular day, we can download the Latitude and Longitude coordinates alongside the Daily_SIF_757nm variable. The value for SIF is colormapped using the viridis colormap by default.\n",
    "\n",
    "The first time you run this code block, you will get a few warnings from cartopy notifying you that it is downloading public resources for displaying the map context, this is expected and not a problem. It may take 20-30 seconds to download all the data, so please be patient.\n",
    "\n",
    "Note that some of the SIF samples have negative values, this is normal and expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_array(variable: str):\n",
    "    return np.array(granule[variable].data[:])\n",
    "\n",
    "# Note: For some datasets, these variables may be called \"latitude\" or \"longitude\"\n",
    "lat = get_variable_array(\"Latitude\")\n",
    "lon = get_variable_array(\"Longitude\")\n",
    "sif = get_variable_array(\"Daily_SIF_757nm\")\n",
    "# Setting vmax to 1.5 W/m^2/sr/μm improves the contrast of the colormapped samples\n",
    "# and is based on a priori knowledge of the data range in this granule\n",
    "# Remove the vmax keyword if you want matplotlib to set the data range automatically\n",
    "plot_samples(\n",
    "    sif, lat, lon,\n",
    "    vmax=1.5,\n",
    "    title=f\"757nm SIF ({data_date.strftime('%Y-%m-%d')})\",\n",
    "    label=\"SIF (W/$\\mathrm{m}^2$/sr/μm)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Download a set of Data (Optional)\n",
    "\n",
    "Now we can download a set of granules across a date range to perform analysis. After gathering the filesizes of the granules, the code will prompt you to confirm the amount of data you are about to download before proceeding. The following cell will download one month of data, but you can try different time ranges.\n",
    "\n",
    "**Troubleshooting**: Some file downloads may fail. You can set `parallel=False` in the function call to improve your odds of success, but simply retrying the operation will only download the files that you do not already have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply put in the year and month you are interested in and the timerange will be\n",
    "# downloaded into a named directory for you (e.g., 2020-06)\n",
    "year = 2020\n",
    "month = 6\n",
    "start_date = datetime(year, month, 1)\n",
    "_, num_days = calendar.monthrange(year, month)\n",
    "end_date = datetime(year, month, num_days)\n",
    "\n",
    "dl_granules, dates_notfound, failed_dls = dl.download_timerange(\n",
    "        dataset,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        outpath=f\"data/{dataset}/{year}-{month:02d}\",\n",
    "        parallel=True,\n",
    "    )\n",
    "\n",
    "if dl_granules:\n",
    "    print(f\"Download summary: Downloaded {len(dl_granules)} out of {num_days} days\")\n",
    "    for granule in sorted(dl_granules):\n",
    "        print(granule.name)\n",
    "\n",
    "if dates_notfound:\n",
    "    print(f\"No data found for {len(dates_notfound)} days:\")\n",
    "    for dt in sorted(dates_notfound):\n",
    "        print(dt.strftime(\"%d/%m/%Y\"))\n",
    "\n",
    "if failed_dls:\n",
    "    print(f\"Failed to download {len(failed_dls)} granules:\")\n",
    "    for url in failed_dls:\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Generate a Mean Daily SIF Product for One Month (PLEASE READ)\n",
    "\n",
    "**Now let's create a gridded mean daily SIF raster from the granules for one month. There are two options for sourcing your data, you only have to run one of these cells:**\n",
    "- **Option A:** Use the locally downloaded files from step III.\n",
    "- **Option B:** Use pydap to download data from GES DISC on the fly, saving you from having to store each day's worth of data.\n",
    "\n",
    "The provided helper functions create a gridded netCDF for the `Daily_SIF_757nm` variable, but you can add to the list of variables if you wish. Note that the data is filtered to use exclusively samples with a `Quality_Flag` of 0, representing the best quality data. You may wish to include points with a `Quality_Flag` of 1 (good).\n",
    "\n",
    "\n",
    "Customizations:\n",
    "- Change the start and end dates specified by the first two arguments to adjust the month referenced for the output product.\n",
    "- Add additional variables to average in the output netCDF (ex: `Daily_SIF_771nm`, `Science_SIF_Relative_757nm`, `Science_daily_correction_factor`, etc.)\n",
    "- Change the name of the output file by changing the value of the `daily_avg_file` variable.\n",
    "- You can also specify a bounding box for the data, such as `lon_min=-130, lat_max=-65, lat_min=22, lat_max=50,` for the CONUS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell regardless of which option you choose\n",
    "year = 2020\n",
    "month = 6\n",
    "start_date = datetime(year, month, 1)\n",
    "_, num_days = calendar.monthrange(year, month)\n",
    "end_date = datetime(year, month, num_days)\n",
    "\n",
    "daily_avg_file = f\"data/{dataset}/{start_date.strftime('%b_%Y').lower()}_sif.nc4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option A:** Use the files you downloaded in Step III to create the gridded raster. This will take about 30 seconds now that you already have the data locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this option, note that local_dataset has the value that is\n",
    "# expected in the filename of your downloaded granules, rather than\n",
    "# the name of the dataset on the DAAC.\n",
    "local_dataset = \"oco3_LtSIF\"\n",
    "create_gridded_raster(\n",
    "    start_date,\n",
    "    end_date,\n",
    "    local_dataset,\n",
    "    [\"Daily_SIF_757nm\"],\n",
    "    daily_avg_file,\n",
    "    lat_res = 0.5,\n",
    "    lon_res = 0.5,\n",
    "    # Uncomment to bound the data to the CONUS\n",
    "    # lon_min=-150, lon_max=-60, lat_min=22, lat_max=50,\n",
    "    local_dir=f\"data/{dataset}/{year}-{month:02d}\",\n",
    "    filters={\n",
    "        # Change Quality_Flag to (\"<\" 2) if you would like to use both best and good quality data\n",
    "        \"Quality_Flag\": (\"=\", 0),\n",
    "        # Filter to Nadir mode observations\n",
    "        # \"Metadata/MeasurementMode\": (\"=\", 0)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option B: Use pydap to download data on the fly. This option uses less disk space but will take about 5 - 10 minutes to finish processing.**\n",
    "\n",
    "You can skip this block and proceed to plotting if you have already generated the `daily_avg_file` referenced in the block above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_gridded_raster(\n",
    "    start_date,\n",
    "    end_date,\n",
    "    dataset,\n",
    "    [\"Daily_SIF_757nm\"],\n",
    "    daily_avg_file,\n",
    "    lat_res = 0.5,\n",
    "    lon_res = 0.5,\n",
    "    # Uncomment to bound the data to the CONUS\n",
    "    # lon_min=-130, lon_max=-65, lat_min=22, lat_max=50,\n",
    "    filters={\n",
    "        # Change Quality_Flag to (\">\" 2) if you would like to use both best and good quality data\n",
    "        \"Quality_Flag\": (\"=\", 0)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Monthly Gridded Raster\n",
    "\n",
    "If you used a different dataset or variable for your monthly gridded raster, be sure to modify the values of `title`, `label`, and `outfile` in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(daily_avg_file, \"r\")\n",
    "var_name = \"Daily_SIF_757nm\"\n",
    "var = ds[var_name]\n",
    "lats = ds[\"lat\"][:]\n",
    "lons = ds[\"lon\"][:]\n",
    "fill_val = var._FillValue\n",
    "\n",
    "daily_avg_data = var[...]\n",
    "ds.close()\n",
    "lon2d, lat2d = np.meshgrid(lons, lats)\n",
    "# Transpose the meshgrid result to be of shape (lon_res, lat_res) ex. (360, 180)\n",
    "lon2d = lon2d.T\n",
    "lat2d = lat2d.T\n",
    "\n",
    "# Create a masked array where the fill_val is masked\n",
    "data_masked = np.ma.masked_where(daily_avg_data == fill_val, daily_avg_data)\n",
    "# Average over axis 0 (the \"time\" dimension), produces a masked array of shape (lon_res, lat_res)\n",
    "mean_data_masked = data_masked.mean(axis=0)\n",
    "\n",
    "# Be sure to change the title and label if you change the monthly gridded raster you want to display\n",
    "# To avoid overwriting the output image when making changes, you should also change the value of outfile\n",
    "plot_gridded(\n",
    "    mean_data_masked, lat2d, lon2d,\n",
    "    vmax=0.8,\n",
    "    vmin=0,\n",
    "    # Uncomment to window the plot to the CONUS\n",
    "    # extents=[-130, -65, 22, 50],\n",
    "    title=f\"OCO-3 {start_date.strftime('%B %Y')} Mean Daily SIF$_{{757}}$\",\n",
    "    label=\"SIF (W/$\\mathrm{m}^2$/sr/μm)\",\n",
    "    outfile=f\"mean_oco3_{var_name.lower()}_{start_date.strftime('%B_%Y').lower()}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Create an OCO-2 XCO<sub>2</sub> Monthly Gridded Raster\n",
    "\n",
    "Next, we will repeat the process of generating and plotting a monthly gridded raster in an abridged manner for an XCO<sub>2</sub> dataset. The process is largely the same, we are just changing the arguments to the functions and labels of plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the dataset-dependent variables\n",
    "dataset = \"OCO2_L2_Lite_FP.11.2r\"\n",
    "local_dataset = \"oco2_LtCO2\" # This is the first part of the filename\n",
    "mission_name = \"OCO-2\"\n",
    "year = 2020\n",
    "month = 6\n",
    "var_name = \"xco2\"\n",
    "var_label = \"XCO$_2$\"\n",
    "unit = \"ppm\"\n",
    "start_date = datetime(year, month, 1)\n",
    "_, num_days = calendar.monthrange(year, month)\n",
    "end_date = datetime(year, month, num_days)\n",
    "\n",
    "granule_dir = f\"data/{dataset}/{year}-{month:02d}\"\n",
    "daily_avg_file = f\"data/{dataset}/{start_date.strftime('%b_%Y').lower()}_{var_name}.nc4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the granules, then generate the raster. XCO<sub>2</sub> granules are three times larger than SIF, so this will grab about 2 GB of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = GesDiscDownloader()\n",
    "dl_granules, dates_notfound, failed_dls = dl.download_timerange(\n",
    "        dataset,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        outpath=granule_dir,\n",
    "        parallel=True,\n",
    "    )\n",
    "\n",
    "if dl_granules:\n",
    "    print(f\"Download summary: Downloaded {len(dl_granules)} out of {num_days} days\")\n",
    "    for granule in sorted(dl_granules):\n",
    "        print(granule.name)\n",
    "\n",
    "if dates_notfound:\n",
    "    print(f\"No data found for {len(dates_notfound)} days:\")\n",
    "    for dt in sorted(dates_notfound):\n",
    "        print(dt.strftime(\"%d/%m/%Y\"))\n",
    "\n",
    "if failed_dls:\n",
    "    print(f\"Failed to download {len(failed_dls)} granules:\")\n",
    "    for url in failed_dls:\n",
    "        print(url)\n",
    "\n",
    "create_gridded_raster(\n",
    "    start_date,\n",
    "    end_date,\n",
    "    local_dataset,\n",
    "    [var_name],\n",
    "    daily_avg_file,\n",
    "    lat_res = 0.5,\n",
    "    lon_res = 0.5,\n",
    "    # Uncomment to bound the data to the CONUS\n",
    "    # lon_min=-130, lon_max=-65, lat_min=22, lat_max=50,\n",
    "    local_dir=granule_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(daily_avg_file, \"r\")\n",
    "var = ds[var_name]\n",
    "lats = ds[\"lat\"][:]\n",
    "lons = ds[\"lon\"][:]\n",
    "fill_val = var._FillValue\n",
    "\n",
    "daily_avg_data = var[...]\n",
    "ds.close()\n",
    "lon2d, lat2d = np.meshgrid(lons, lats)\n",
    "# Transpose the meshgrid result to be of shape (lon_res, lat_res) ex. (360, 180)\n",
    "lon2d = lon2d.T\n",
    "lat2d = lat2d.T\n",
    "\n",
    "# Create a masked array where the fill_val is masked\n",
    "data_masked = np.ma.masked_where(daily_avg_data == fill_val, daily_avg_data)\n",
    "# Average over axis 0 (the \"time\" dimension), produces a masked array of shape (lon_res, lat_res)\n",
    "mean_data_masked = data_masked.mean(axis=0)\n",
    "\n",
    "# Be sure to change the title and label if you change the monthly gridded raster you want to display\n",
    "# To avoid overwriting the output image when making changes, you should also change the value of outfile\n",
    "plot_gridded(\n",
    "    mean_data_masked, lat2d, lon2d,\n",
    "    vmin=405,\n",
    "    vmax=420,\n",
    "    # Uncomment to window the plot to the CONUS\n",
    "    # extents=[-130, -65, 22, 50],\n",
    "    title=f\"{mission_name} {start_date.strftime('%B %Y')} Mean Daily {var_label}\",\n",
    "    label=f\"{var_label} ({unit})\",\n",
    "    outfile=f\"mean_{mission_name.lower()}_{var_name.lower()}_{start_date.strftime('%B_%Y').lower()}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
