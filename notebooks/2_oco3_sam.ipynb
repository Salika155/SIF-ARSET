{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92dcfa6a",
   "metadata": {},
   "source": [
    "# OCO-3 Snapshot Area Map (SAM) Exploration\n",
    "\n",
    "WWhile OCO-2 and OCO-3 share the same spectrometer design, OCO-3 introduces a key innovation: the Pointing Mirror Assembly (PMA). This PMA enables rapid reorienting of the instrument's field of view, allowing data collection over contiguous 80 km × 80 km areas called Snapshot Area Maps (SAMs). These SAMs provide spatially dense SIF measurements that capture fine-scale heterogeneity in vegetation photosynthesis. The OCO-3 science team maintains an archive of SAM acquisitions at [https://ocov3.jpl.nasa.gov/sams/](https://ocov3.jpl.nasa.gov/sams/)\n",
    "\n",
    "In this notebook, we will analyze a time series of SAMs centered on the University of Michigan Biological Station (UMBS) in northern Michigan, USA. This site sits within a deciduous broadleaf forest ecosystem with >60% vegetation cover, interspersed with small agricultural areas and rural communities. By examining SAMs acquired across different seasons, we will:\n",
    "\n",
    "1. Quantify the seasonal dynamics of SIF in this temperate forest ecosystem. Additionally, data has been prepared for you in the homework exercise that covers an evergreen needleleaf forest.\n",
    "2. Compare OCO-3 SIF observations with ground-based gross primary productivity (GPP) measurements from the [AmeriFlux eddy covariance tower (US-UMB)](https://ameriflux.lbl.gov/sites/siteinfo/US-UMB) \n",
    "3. Explore the spatial patterns of photosynthetic activity across the study region\n",
    "\n",
    "This exercise will demonstrate how SAMs can bridge the gap between the high temporal resolution of tower measurements and the high spatial coverage of satellite observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "from cartopy import crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from datetime import datetime\n",
    "import json\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import sys\n",
    "\n",
    "\n",
    "# Add src directory containing helper code to sys.path\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from pysif import GesDiscDownloader, plot_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e7602",
   "metadata": {},
   "source": [
    "## I. Retrieving SAM Data\n",
    "\n",
    "The [SAM webpage](https://ocov3.jpl.nasa.gov/sams/index.php) mentioned previously is a great place to start for finding specific sites and observations. In this exercise, we will be looking at the `sif_University_of_Michigan_USA` site, but you can pan through the map on the webpage to find a different area of interest on your own. The homework exercise covers the `ecostress_us_me2` site as an additional example.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/sif_uofm_usa_map.png\" alt=\"sif_University_of_Michigan_USA SAM site map pin\">\n",
    "</div>\n",
    "\n",
    "If you put the site name and the site type (\"SIF_High\", which can be found by clicking on the map pin for the site as can be seen in the figure above) into the search parameters, a list of all SAM observations at that site will be pulled up.\n",
    "\n",
    "* Site name: `sif_University_of_Michigan_USA`\n",
    "* Site type: `SIF_High`\n",
    "\n",
    "These search results can tell us which dates we want to retrieve SIF granules for, and then filter those granules to only include soundings from the SAM mode, which is `Metadata_MeasurementMode` 3 in the granule. To perform the retrieval and plotting, we can use the same code from the first exercise (1_exploration.ipynb). For the best possible plot, let's choose a SAM snapshot with a non-zero number of soundings. A good example of this occurred on August 11th, 2020:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/sam_search_result.png\" alt=\"SAM mode search result\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa69bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = GesDiscDownloader()\n",
    "\n",
    "dataset = \"OCO3_L2_Lite_SIF.11r\"\n",
    "data_date = datetime(2020, 8, 11)\n",
    "granule = dl.get_granule_by_date(dataset, data_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bfb117",
   "metadata": {},
   "source": [
    "Now that we have the granule, we can filter the data to just SAM soundings. You can find more information about OCO-3's measurement modes in the [User's Guide](https://docserver.gesdisc.eosdis.nasa.gov/public/project/OCO/OCO2_v11.2_OCO3_v11_SIF_Data_Users_Guide.pdf), see Section 4.7 \"The Metadata Group\". Measurement Mode 3 is referred to as an AreaMap -- this is the SAM mode we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e560e5f-bc28-4348-bc34-96090e489a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sam_extent is determined manually by inspecting the official SAM mode plot\n",
    "# If you choose a different date or tower site, adjust these values accordingly!\n",
    "sam_extent = [-86.8, -83.9, 44.7, 46.5]\n",
    "\n",
    "# Get the measurement mode of the data first so we can filter to just use SAM mode soundings\n",
    "# Additionally, we will remove low quality soundings\n",
    "meas_mode = np.array(granule[\"Metadata_MeasurementMode\"].data[:])\n",
    "qual_flag = np.array(granule[\"Quality_Flag\"].data[:])\n",
    "sam_mask  = (meas_mode == 3) & ((qual_flag == 0) | (qual_flag == 1))\n",
    "\n",
    "all_lat = granule[\"Latitude\"].data[:]\n",
    "all_lon = granule[\"Longitude\"].data[:]\n",
    "all_sif = granule[\"Daily_SIF_757nm\"].data[:]\n",
    "\n",
    "lat = all_lat[sam_mask]\n",
    "lon = all_lon[sam_mask]\n",
    "sif = all_sif[sam_mask]\n",
    "\n",
    "# Using the plot_samples function from the first notebook gives us a good first look at this data\n",
    "# before further processing. The YlGn colormap is used to make it easier to compare the data with\n",
    "# the official plot.\n",
    "plot_samples(\n",
    "    sif, lat, lon,\n",
    "    vmin=0.21,\n",
    "    vmax=0.64,\n",
    "    cmap=\"YlGn\",\n",
    "    point_size=15,\n",
    "    fig_size=(8, 8),\n",
    "    extents=sam_extent,\n",
    "    title=f\"OCO-3 SAM mode LtSIF 757 nm ({data_date.strftime('%Y-%m-%d')})\",\n",
    "    label=r\"Daily SIF 757 nm (W/$\\mathrm{m}^2$/sr/μm)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c29594",
   "metadata": {},
   "source": [
    "### Comparison with official plot\n",
    "If you've been following along on the OCO-3 website, you may have noticed that the science team provides pre-made plots of a variety of measurements for each SAM acquisition. Let's take a look at one of these plots for the OCO-3 LtSIF 757nm variable:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img style=\"width:640px\" src=\"images/OCO3_Lite_B11074Ar_r02_sif_757nm_20200811_7215_sif_umb.png\" alt=\"Official OCO-3 SAM mode plot over UMBS tower site for August 11, 2020\">\n",
    "</div>\n",
    "\n",
    "If the previous code ran successfully for you, you should be able to see that we are at least looking at the same data but with some superficial differences in presentation. In the next section, we will refine our plot to look like the official version. The most important component of this will be to adjust each sounding to use its proper footprint extents. We will also add a marker to the plot to indicate the location of the tower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce11ac-54e1-4044-8f6d-98e97ae030a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to specify the location of the tower as a (longitude, latitude)\n",
    "tower_lonlat = (-84.7138, 45.5598)\n",
    "vmin = 0.21\n",
    "vmax = 0.64\n",
    "\n",
    "\n",
    "def plot_sam(\n",
    "        granule,\n",
    "        extent: list[float],\n",
    "        tower_site: tuple[float, float] = (-1, -1),\n",
    "        vmin: float = -0.05,\n",
    "        vmax: float = 0.55,\n",
    ") -> None:\n",
    "    # Perform the same filtering step as in the previous code block\n",
    "    meas_mode = np.array(granule[\"Metadata_MeasurementMode\"].data[:])\n",
    "    qual_flag = np.array(granule[\"Quality_Flag\"].data[:])\n",
    "    sam_mask  = (meas_mode == 3) & ((qual_flag == 0) | (qual_flag == 1))\n",
    "    \n",
    "    # Instead of using latitude and longitude directly, we will now apply the\n",
    "    # footprint vertices when plotting SIF samples\n",
    "    all_footlat = granule[\"Geolocation_footprint_latitude_vertices\"].data[:]\n",
    "    all_footlon = granule[\"Geolocation_footprint_longitude_vertices\"].data[:]\n",
    "    footprint_lat = all_footlat[sam_mask][:]\n",
    "    footprint_lon = all_footlon[sam_mask][:]\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.GOOGLE_MERCATOR)\n",
    "\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Add a marker with the tower location to the plot. These coordinates can be found on the Ameriflux site\n",
    "    if tower_site != (-1, -1):\n",
    "        ax.plot(tower_site[0], tower_site[1], marker='*', color='red', markersize=10, transform=ccrs.Geodetic())\n",
    "\n",
    "    patches_list = []\n",
    "    for i in range(len(sif)):\n",
    "        polygon = patches.Polygon(np.column_stack([footprint_lon[i], footprint_lat[i]]))\n",
    "        patches_list.append(polygon)\n",
    "\n",
    "    pcol = PatchCollection(\n",
    "        patches_list,\n",
    "        cmap=\"YlGn\",\n",
    "        transform=ccrs.PlateCarree()\n",
    "    )\n",
    "\n",
    "    pcol.set_array(np.array(sif))\n",
    "    pcol.set_clim(vmin, vmax)\n",
    "    sif_layer = ax.add_collection(pcol)\n",
    "\n",
    "    # Zoom level 9 strikes a balance between detail in the map base layer and\n",
    "    # execution time when creating the plot. If you have a slow internet connection,\n",
    "    # try decreasing the zoom value to 7 or 8.\n",
    "    ctx.add_basemap(\n",
    "        ax,\n",
    "        source=ctx.providers.Esri.WorldImagery,\n",
    "        crs=ccrs.GOOGLE_MERCATOR,\n",
    "        zoom=9\n",
    "    )\n",
    "\n",
    "    # Add gridlines over the map. Note that we can use the default LATITUDE_FORMATTER and\n",
    "    # LONGITUDE_FORMATTER from cartopy to make our lives easier\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color=\"white\", alpha=0.7, linestyle=\"-\")\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {\"size\": 14, \"color\": \"black\"}\n",
    "    gl.ylabel_style = {\"size\": 14, \"color\": \"black\"}\n",
    "\n",
    "    plt.title(f\"OCO-3 SAM mode LtSIF 757 nm ({data_date.strftime(\"%Y-%m-%d\")})\", fontsize=16)\n",
    "    cbar = plt.colorbar(sif_layer, ax=ax, extend=\"both\", pad=0.01)\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "    cbar.set_label(r\"Daily SIF 757 nm [W/$\\mathrm{m}^2$/sr/μm]\", fontsize=16, rotation=270, labelpad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sam(granule, sam_extent, tower_lonlat, vmin, vmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34a3169",
   "metadata": {},
   "source": [
    "## II. Using Ground-Based Data from an Ameriflux Tower\n",
    "\n",
    "[Eddy covariance (EC)](https://en.wikipedia.org/wiki/Eddy_covariance) flux towers continuously measure carbon dioxide exchange between ecosystems and the atmosphere. These towers provide high-frequency measurments, typically every 30 minutes, of climatology as well as two key variables related to SIF:\n",
    "\n",
    "* **Net Ecosystem Exchange (NEE)**: The net CO₂ flux between the ecosystem and atmosphere\n",
    "* **Gross Primary Production (GPP)**: Total photosynthetic carbon uptake by vegetation.\n",
    "\n",
    "The observed area extends approximately 1 km around the tower, so despite the low spatial coverage the high temporal resolution enables flux towers to act as a ground truth for satellite observations. The figure below illustrates how tower measurements bridge the scale gap between leaf-level measurements and remote sensing:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img style=\"width:640px\" src=\"images/scale.png\" alt=\"A diagram showing the scale of various methods for measuring vegetation primary productivity\">\n",
    "</div>\n",
    "\n",
    "### Working with Ameriflux Data\n",
    "\n",
    "To begin, we will plot the GPP data contained in the provided `AMF_US-UMB_FLUXNET_SUBSET_DD_2019-2021.csv` file. This file was obtained using the \"Download Data\" functionality on the [Ameriflux page for the tower](https://ameriflux.lbl.gov/sites/siteinfo/US-UMB). Downloading data requires an account, so this step has already been done for your convenience. The Ameriflux data is presented at several time scales ranging from yearly to hourly, and for this analysis we are just using the daily data. An abridged version of the daily data is included in the notebooks directory containing just the entries for August 2019 through the end of 2021. A guide to the filename convention is included to help with understanding the characteristics of the data:\n",
    "\n",
    "> `AMF_US-UMB_FLUXNET_SUBSET_DD_2019-2021.csv`\n",
    "> * `AMF` = Ameriflux network data\n",
    "> * `US-UMB` = tower site code, United States University of Michigan Biological (Station)\n",
    "> * `FLUXNET` = fluxnet data, as opposed to BADM, BASE, or other datasets. Note that BASE datasets do not contain GPP.\n",
    "> * `SUBSET` = this file contains only a subset of the full set of measurements available for the tower. The available measurements are documented on the webpage.\n",
    "> * `DD` = Daily time cadence\n",
    "> * `2019-2021` = File has been edited to contain only relevant dates. This is a subset of the original 2007-2021 date range for this site.\n",
    "\n",
    "**In the following code block, we will compare two methods for retrieving GPP, the Daytime (DT) and Nighttime (NT) partionining Variable Ustar Threshold (VUT) algorithms. We will also plot the OCO-3 SIF values from the same period using a spatial averaging technique described in the next section.**\n",
    "\n",
    "For more information on the theoretical basis of these GPP retrievals, please read the following papers:\n",
    "\n",
    "* [Pastorello et al., 2020](https://doi.org/10.1038/s41597-020-0534-3): description of the FLUXNET pipeline\n",
    "* [Lasslop et al., 2010](https://doi.org/10.1111/j.1365-2486.2009.02041.x): daytime partitioning algorithm for GPP/NEE\n",
    "* [Reichstein et al., 2005](https://doi.org/10.1111/j.1365-2486.2005.001002.x): nighttime partitioning algorithm for GPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27758808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths: If you want to study a different tower like the us_me2 example, modify the file paths here\n",
    "gpp_file = \"AMF_US-UMB_FLUXNET_SUBSET_DD_2019-2021.csv\"\n",
    "sif_file = \"us_umb_oco3_sif.json\"\n",
    "\n",
    "# gpp_file = \"AMF_US-Me2_FLUXNET_SUBSET_DD_2019-2022.csv\"\n",
    "# sif_file = \"us_me2_oco3_sif.json\"\n",
    "\n",
    "# Load SIF observation data\n",
    "def load_sif_data(json_file):\n",
    "    \"\"\"Load SIF observation data from JSON file, excluding dates with SIF = 0\"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract dates and SIF values where SIF > 0\n",
    "    sif_data = [(pd.to_datetime(item[\"date\"]), item[\"sif\"]) \n",
    "                for item in data[\"dates\"] if item[\"sif\"] != 0]\n",
    "    \n",
    "    sif_dates = [item[0] for item in sif_data]\n",
    "    sif_values = [item[1] for item in sif_data]\n",
    "    \n",
    "    return sif_dates, sif_values\n",
    "\n",
    "# Read the GPP file\n",
    "tower_name = gpp_file.split(\"_\")[1]\n",
    "date_range = gpp_file.split(\"_\")[5].strip(\".csv\")\n",
    "\n",
    "# strip metadata rows that start with #\n",
    "df = pd.read_csv(gpp_file, comment='#')\n",
    "\n",
    "# FLUXNET daily timestamps are yyyymmdd as an int/str.\n",
    "df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'], format='%Y%m%d')\n",
    "df = df.set_index('TIMESTAMP')\n",
    "\n",
    "# Get the two \"REF\" GPP columns\n",
    "cols = [\n",
    "    \"GPP_NT_VUT_REF\",\n",
    "    \"GPP_DT_VUT_REF\"\n",
    "]\n",
    "gpp = df[cols]\n",
    "\n",
    "# Load SIF observation data, if available\n",
    "try:\n",
    "    sif_dates, sif_values = load_sif_data(sif_file)\n",
    "    \n",
    "    # Create the plot with dual y-axes\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Plot GPP time series on primary y-axis\n",
    "    gpp.plot(ax=ax1, linewidth=1.5, alpha=0.8)\n",
    "    ax1.set_xlabel(\"Date\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Tower GPP [gC/m²/day]\", fontsize=12, color='black')\n",
    "    ax1.tick_params(axis='y', labelcolor='black')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Create secondary y-axis for SIF\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.scatter(sif_dates, sif_values, color='red', marker='o', s=50, \n",
    "               alpha=0.7, edgecolors='darkred', linewidth=0.5, \n",
    "               label='SIF Observations', zorder=5)\n",
    "    ax2.set_ylabel(r'OCO-3 SIF [W/m²/sr/μm]', fontsize=12, color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    plt.title(f\"Daily GPP (NT vs DT VUT) and SIF Observations for {tower_name}, {date_range}\", fontsize=14)\n",
    "    \n",
    "    # Combine legends from both axes\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, \n",
    "              loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find SIF file - {e}\")\n",
    "    # Fallback: plot without SIF markers\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    gpp.plot(ax=plt.gca())\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Tower GPP [gC/m²/day]\")\n",
    "\n",
    "    plt.title(f\"Daily GPP (NT vs DT VUT) for {tower_name}, {date_range}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading SIF data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbab0645",
   "metadata": {},
   "source": [
    "### What can we notice about this plot?\n",
    "\n",
    "The two GPP partitioning methods (DT and NT) show strong agreement throughout the observation period at US-UMB. This consistency indicates robust flux measurements and stable ecosystem behavior. Note that algorithm divergence can occur at some sites, and you'll observe this phenomenon in the US-Me2 homework dataset around summer 2022.\n",
    "\n",
    "Another key observation is that the data reveal distinct phenological patterns characteristic of deciduous broadleaf forests:\n",
    "\n",
    "* **Growing season (May–October)**: Peak GPP values reaching ~15 gC m⁻² day⁻¹\n",
    "* **Dormant season (November–April)**: Near-zero GPP during leafless periods\n",
    "* **Transitions**: Rapid changes during spring leaf-out and autumn senescence\n",
    "\n",
    "This seasonality contrasts with evergreen forests, which exhibit some measurable GPP and SIF at a reduced level throughout winter months. \n",
    "\n",
    "The SIF observations from OCO-3, denoted by the red markers, are reasonably well correlated with the GPP data even despite being different measurements acquired by different instruments at vastly different resolutions. This suggests that the SIF signal we are getting from OCO-3 is effectively capturing ecosystem-scale photosynthesis and that both measurements respond similarly to environmental factors.\n",
    "\n",
    "**Question: How do you expect an ecological disruption would affect the ability to discern a SIF-GPP relationship between OCO-3 data and tower data? Try replacing the files in the previous code block and the next with the provided CSV and JSON for the US-Me2 site. What can you observe about that data that looks different from the US-UMB site?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae25c651",
   "metadata": {},
   "source": [
    "## III. Comparison of OCO-3 SIF with Ameriflux Tower GPP Data\n",
    "\n",
    "In this section, we will compare daily averaged SIF from OCO-3 against tower GPP data from the US-UMB site. Ultimately, we will create a daily time-scale plot comparing available data from the two datasets over the period from August 2019 (the beginning of the OCO-3 mission) through the end of 2021 (the end of the Ameriflux data for this tower as of the writing of this training). This plot will look similar to figure 3b from [Pierrat et al., 2022](https://doi.org/10.1029/2021JG006588). \n",
    "\n",
    "If you wish to explore the data from that paper and other tower-based SIF and GPP measurements further, you can find the associated dataset here: \n",
    "* [https://doi.org/10.5281/zenodo.10048770](https://doi.org/10.5281/zenodo.10048770): Zenodo data store with tower SIF at various sites\n",
    "* [https://climatesciences.jpl.nasa.gov/sif/download-data/tower/](https://climatesciences.jpl.nasa.gov/sif/download-data/tower/): A curated list of towers that have SIF data. Remember that because OCO-3 has only been operating since 2019, not all tower sites will have data records that overlap with OCO-3.\n",
    "\n",
    "### Pre-processing\n",
    "\n",
    "Several pre-processing steps have already been taken for you. First, you will notice there is an ancillary file called \"us_umb_oco3_dates.json\" in the same directory as this notebook. This JSON file was created by studying all available data dates across the OCO-3 mission from August 2019 - December 2021 to determine which samples lie within a 0.5-degree radius around the tower site. This search process was performed using the code in the Appendix notebook, so we will just discuss it conceptually here. By looping through each date in the time range of interest, we can search for (longitude, latitude) coordinate pairs that lie within the defined bounding box: in this case, $\\pm 0.25^{\\circ}$ around the tower coordinates. In the next part of the pre-processing, we extract the relevant data from each discovered granule and take the mean of all 757nm SIF data with a Quality Flag value of 0 (best) or 1 (good). The spatial means are stored in a separate JSON file called \"us_umb_oco3_sif.json\" that will be used as the basis for our daily SIF values in the comparison plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "gpp_file = \"AMF_US-UMB_FLUXNET_SUBSET_DD_2019-2021.csv\"\n",
    "sif_file = \"us_umb_oco3_sif.json\"\n",
    "\n",
    "# gpp_file = \"AMF_US-Me2_FLUXNET_SUBSET_DD_2019-2022.csv\"\n",
    "# sif_file = \"us_me2_oco3_sif.json\"\n",
    "\n",
    "# Change this to use a different GPP column, e.g., GPP_DT_VUT_REF\n",
    "# For US-UMB, this has little effect on the regression\n",
    "gpp_column = \"GPP_NT_VUT_REF\"\n",
    "\n",
    "\n",
    "def load_sif_data(json_file):\n",
    "    \"\"\"Load SIF data from JSON file\"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data[\"dates\"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df\n",
    "\n",
    "def load_gpp_data(csv_file, gpp_column=\"GPP_NT_VUT_REF\"):\n",
    "    \"\"\"Load GPP data from CSV file\"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Convert TIMESTAMP to datetime\n",
    "    df[\"date\"] = pd.to_datetime(df[\"TIMESTAMP\"], format=\"%Y%m%d\")\n",
    "    \n",
    "    # Select relevant columns\n",
    "    df = df[[\"date\", gpp_column]].copy()\n",
    "    df.rename(columns={gpp_column: \"gpp\"}, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_temporal_features(data):\n",
    "    \"\"\"Add year and season columns to the data\"\"\"\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Extract year\n",
    "    data[\"year\"] = data[\"date\"].dt.year\n",
    "    \n",
    "    # Extract month and map to seasons\n",
    "    month = data[\"date\"].dt.month\n",
    "    data[\"season\"] = month.map({\n",
    "        12: \"winter\", 1: \"winter\", 2: \"winter\",\n",
    "        3: \"spring\", 4: \"spring\", 5: \"spring\",\n",
    "        6: \"summer\", 7: \"summer\", 8: \"summer\",\n",
    "        9: \"autumn\", 10: \"autumn\", 11: \"autumn\"\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "def merge_and_clean_data(sif_df, gpp_df):\n",
    "    \"\"\"Merge SIF and GPP data on date and remove invalid values\"\"\"\n",
    "    # Merge on date\n",
    "    merged = pd.merge(sif_df, gpp_df, on=\"date\", how=\"inner\")\n",
    "    \n",
    "    # Remove rows with NaN or negative values\n",
    "    merged = merged.dropna()\n",
    "    \n",
    "    # Remove rows where GPP is the fill value, -9999\n",
    "    merged = merged[merged[\"gpp\"] != -9999]\n",
    "    merged = merged[merged[\"sif\"] != 0]\n",
    "    \n",
    "    # Add temporal features\n",
    "    merged = add_temporal_features(merged)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def create_scatter_plot(data, gpp_column_name=\"GPP_NT_VUT_REF\", mark_years=False, print_stats=False):\n",
    "    \"\"\"Create scatter plot with linear regression, seasonal colors, and yearly markers\"\"\"\n",
    "    # Extract x and y values\n",
    "    x = data[\"sif\"].values.reshape(-1, 1)\n",
    "    y = data[\"gpp\"].values\n",
    "\n",
    "    # Fit linear regression\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(x, y)\n",
    "    y_pred = reg.predict(x)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Define color mapping for seasons\n",
    "    season_colors = {\n",
    "        \"winter\": \"blue\",\n",
    "        \"spring\": \"green\",\n",
    "        \"summer\": \"gold\",\n",
    "        \"autumn\": \"red\"\n",
    "    }\n",
    "    \n",
    "    if mark_years:\n",
    "        year_markers = {\n",
    "            2019: \"o\",  # circle\n",
    "            2020: \"s\",  # square\n",
    "            2021: \"^\",  # triangle up\n",
    "            2022: \"D\"   # diamond\n",
    "        }\n",
    "        title_addon = \" | Markers: Years\"\n",
    "    else:\n",
    "        year_markers = {y: \"o\" for y in range(2019, 2023)}\n",
    "        title_addon = \"\"\n",
    "    \n",
    "    # Create scatter plot with seasonal colors and yearly markers\n",
    "    for year in sorted(data[\"year\"].unique()):\n",
    "        for season in [\"winter\", \"spring\", \"summer\", \"autumn\"]:\n",
    "            # Filter data for this year and season\n",
    "            mask = (data[\"year\"] == year) & (data[\"season\"] == season)\n",
    "            subset = data[mask]\n",
    "            \n",
    "            if len(subset) > 0:\n",
    "                plt.scatter(\n",
    "                    subset[\"sif\"], \n",
    "                    subset[\"gpp\"],\n",
    "                    c=season_colors[season],\n",
    "                    marker=year_markers[year],\n",
    "                    s=60,\n",
    "                    alpha=0.7,\n",
    "                    edgecolors=\"black\",\n",
    "                    linewidth=0.5,\n",
    "                    label=f\"{year} {season}\" if len(plt.gca().get_legend_handles_labels()[0]) < 16 else \"\"\n",
    "                )\n",
    "    \n",
    "    # Plot regression line\n",
    "    x_sorted = np.sort(data[\"sif\"].values)\n",
    "    y_pred_sorted = reg.predict(x_sorted.reshape(-1, 1))\n",
    "    plt.plot(x_sorted, y_pred_sorted, color=\"black\", linewidth=2, linestyle=\"--\", alpha=0.8)\n",
    "    \n",
    "    # Add R² value to plot\n",
    "    plt.text(0.05, 0.95, f\"R² = {r2:.3f}\", \n",
    "             transform=plt.gca().transAxes, \n",
    "             fontsize=12, \n",
    "             verticalalignment=\"top\",\n",
    "             bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n",
    "    \n",
    "    # Labels and title\n",
    "    plt.xlabel(r\"OCO-3 SIF [W/$\\mathrm{m}^2$/sr/μm]\", fontsize=12)\n",
    "    plt.ylabel(f\"Tower GPP ({gpp_column_name}) \" + r\"[gC/$\\mathrm{m}^2$/day]\", fontsize=12)\n",
    "    plt.title(f\"Solar-Induced Fluorescence (SIF) vs Gross Primary Productivity (GPP)\\nColors: Seasons{title_addon}\", fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Season legend (colors)\n",
    "    season_handles = [plt.scatter([], [], c=color, s=60, marker='o', edgecolors=\"black\", linewidth=0.5) \n",
    "                     for season, color in season_colors.items()]\n",
    "    season_labels = [season.capitalize() for season in season_colors.keys()]\n",
    "\n",
    "    legend1 = plt.legend(season_handles, season_labels,\n",
    "                         loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=4)\n",
    "    #                    loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    if mark_years:\n",
    "        # Year legend (markers)\n",
    "        year_handles = [plt.scatter([], [], c='gray', marker=marker, s=60, edgecolors=\"black\", linewidth=0.5) \n",
    "                    for year, marker in year_markers.items()]\n",
    "        year_labels = [str(year) for year in year_markers.keys()]\n",
    "\n",
    "        legend2 = plt.legend(year_handles, year_labels, title=\"Years\", \n",
    "                            loc='upper left', bbox_to_anchor=(1.02, 0.7))\n",
    "        \n",
    "        # Add the first legend back (matplotlib removes it when creating the second)\n",
    "        plt.gca().add_artist(legend1)\n",
    "    \n",
    "    if print_stats:\n",
    "        # Print statistics\n",
    "        print(f\"Number of matched data points: {len(data)}\")\n",
    "        print(f\"Linear regression equation: y = {reg.coef_[0]:.3f}x + {reg.intercept_:.3f}\")\n",
    "        print(f\"R² value: {r2:.3f}\")\n",
    "        print(f\"Slope: {reg.coef_[0]:.3f}\")\n",
    "        print(f\"Intercept: {reg.intercept_:.3f}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    sif_data = load_sif_data(sif_file)\n",
    "    \n",
    "    gpp_data = load_gpp_data(gpp_file, gpp_column)\n",
    "    \n",
    "    merged_data = merge_and_clean_data(sif_data, gpp_data)\n",
    "    \n",
    "    # Set mark_years to True if you would like different years of data\n",
    "    # to receive different markers on the plot\n",
    "    # Set print_stats to True if you would like a printout of info\n",
    "    # about the linear regression\n",
    "    create_scatter_plot(\n",
    "        merged_data,\n",
    "        gpp_column,\n",
    "        mark_years=False,\n",
    "        print_stats=False\n",
    "    ) \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c00ce7",
   "metadata": {},
   "source": [
    "### What can we notice about this plot?\n",
    "\n",
    "Our R² result of 0.73 suggests that these variables are well correlated, and is only a little less than the R² reported from comparing daily tower SIF to daily GPP in Pierrat, et al. 2022. We can improve the correlation further by filtering the data on biome type as will be discussed later.\n",
    "\n",
    "The plot also can aid with identifying potential biases in the data. The three points far to the right side of the regression line indicate days where SIF was high but GPP was lower than might be expected. We can look at the SAM plot for one of these days to see if there are any pitfalls to our spatial aggregation technique that might introduce issues in the comparison.\n",
    "\n",
    "The summer data point furthest to the right corresponds to the date 2021-06-02, which can be found by searching through the source JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb71546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow the same procedure as in Section 1 but for 2021-05-28\n",
    "data_date_2 = datetime(2021, 6, 2)\n",
    "# Extent may need to be modified slightly to investigate other SAM mode acquisitions\n",
    "sam_extent_2 = [-85.9, -82.8, 44.9, 47]\n",
    "granule = dl.get_granule_by_date(dataset, data_date_2)\n",
    "\n",
    "vmin = 0.21\n",
    "vmax = 0.82\n",
    "\n",
    "# This function is defined in Section I, so re-run those cells if this doesn't work\n",
    "plot_sam(granule, sam_extent_2, tower_lonlat, vmin, vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182aa62",
   "metadata": {},
   "source": [
    "In the above plot, we can see that while there are some large SIF values near the tower, some are also quite low. Despite the high data availability in this example, there are still gaps caused by clouds and low quality data. SAM observations, despite providing improved spatial coverage compared with the more common nadir and glint modes, must be spatially aggregated to account for cases when a SIF sample may not fall over the precise location of the tower and to reduce the effects of surface anisotropy. One challenge of spatial aggregation is that SIF can vary widely throughout a small area and even between adjacent samples. In this example, there are many potential reasons for the higher than expected SIF average, but one area to consider is the region of agricultural fields to the east of the tower with high SIF values. It is often useful to examine satellite imagery of your study region to determine the unique characteristics of both the site and its surrounding context.\n",
    "\n",
    "Depending on the context of the tower site in your own research, it is worth considering the following additional techiques:\n",
    "\n",
    "* **Reducing the spatial aggregation window**, which will reduce the number of samples considered but potentially exclude non-representative biomes. In the appendix, you can test this by reducing the value of the `tolerance` variable to 0.125\n",
    "* **Filtering data by biome type**, this can allow you to consider a wider spatial window while still taking into account varying biomes. In the appendix, you can test this by uncommenting this portion of the filtering step: `cond = (qual_flag < 2) & ((igbp_type == 4) + (igbp_type == 5))`\n",
    "* **Correlating the local solar time of the SAM data to hourly tower data**. Each data point in a granule contains a UTC time associated with the overflight time. As SAMs are acquired over a period of several minutes, this can be compared with the nearest hour in the tower GPP data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
